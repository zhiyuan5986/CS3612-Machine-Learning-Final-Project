{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "# from torchvision.transforms import ToTensor, Lambda\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NN(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super(NN, self).__init__()\n",
    "\n",
    "#         self.block_1 = nn.Sequential(\n",
    "#                 nn.Conv2d(in_channels=1,\n",
    "#                           out_channels=64,\n",
    "#                           kernel_size=(3, 3),\n",
    "#                           stride=(1, 1),\n",
    "#                           # (1(32-1)- 32 + 3)/2 = 1\n",
    "#                           padding=1), \n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Conv2d(in_channels=64,\n",
    "#                           out_channels=64,\n",
    "#                           kernel_size=(3, 3),\n",
    "#                           stride=(1, 1),\n",
    "#                           padding=1),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.MaxPool2d(kernel_size=(2, 2),\n",
    "#                              stride=(2, 2))\n",
    "#         )\n",
    "        \n",
    "#         self.block_2 = nn.Sequential(\n",
    "#                 nn.Conv2d(in_channels=64,\n",
    "#                           out_channels=128,\n",
    "#                           kernel_size=(3, 3),\n",
    "#                           stride=(1, 1),\n",
    "#                           padding=1),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Conv2d(in_channels=128,\n",
    "#                           out_channels=128,\n",
    "#                           kernel_size=(3, 3),\n",
    "#                           stride=(1, 1),\n",
    "#                           padding=1),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.MaxPool2d(kernel_size=(2, 2),\n",
    "#                              stride=(2, 2))\n",
    "#         )\n",
    "        \n",
    "#         self.block_3 = nn.Sequential(        \n",
    "#                 nn.Conv2d(in_channels=128,\n",
    "#                           out_channels=256,\n",
    "#                           kernel_size=(3, 3),\n",
    "#                           stride=(1, 1),\n",
    "#                           padding=1),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Conv2d(in_channels=256,\n",
    "#                           out_channels=256,\n",
    "#                           kernel_size=(3, 3),\n",
    "#                           stride=(1, 1),\n",
    "#                           padding=1),\n",
    "#                 nn.ReLU(),        \n",
    "#                 nn.Conv2d(in_channels=256,\n",
    "#                           out_channels=256,\n",
    "#                           kernel_size=(3, 3),\n",
    "#                           stride=(1, 1),\n",
    "#                           padding=1),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Conv2d(in_channels=256,\n",
    "#                           out_channels=256,\n",
    "#                           kernel_size=(3, 3),\n",
    "#                           stride=(1, 1),\n",
    "#                           padding=1),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.MaxPool2d(kernel_size=(2, 2),\n",
    "#                              stride=(2, 2))\n",
    "#         )\n",
    "        \n",
    "          \n",
    "#         self.block_4 = nn.Sequential(   \n",
    "#                 nn.Conv2d(in_channels=256,\n",
    "#                           out_channels=512,\n",
    "#                           kernel_size=(3, 3),\n",
    "#                           stride=(1, 1),\n",
    "#                           padding=1),\n",
    "#                 nn.ReLU(),        \n",
    "#                 nn.Conv2d(in_channels=512,\n",
    "#                           out_channels=512,\n",
    "#                           kernel_size=(3, 3),\n",
    "#                           stride=(1, 1),\n",
    "#                           padding=1),\n",
    "#                 nn.ReLU(),        \n",
    "#                 nn.Conv2d(in_channels=512,\n",
    "#                           out_channels=512,\n",
    "#                           kernel_size=(3, 3),\n",
    "#                           stride=(1, 1),\n",
    "#                           padding=1),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Conv2d(in_channels=512,\n",
    "#                           out_channels=512,\n",
    "#                           kernel_size=(3, 3),\n",
    "#                           stride=(1, 1),\n",
    "#                           padding=1),\n",
    "#                 nn.ReLU(),   \n",
    "#                 nn.MaxPool2d(kernel_size=(2, 2),\n",
    "#                              stride=(2, 2))\n",
    "#         )\n",
    "        \n",
    "#         self.block_5 = nn.Sequential(\n",
    "#                 nn.Conv2d(in_channels=512,\n",
    "#                           out_channels=512,\n",
    "#                           kernel_size=(3, 3),\n",
    "#                           stride=(1, 1),\n",
    "#                           padding=1),\n",
    "#                 nn.ReLU(),            \n",
    "#                 nn.Conv2d(in_channels=512,\n",
    "#                           out_channels=512,\n",
    "#                           kernel_size=(3, 3),\n",
    "#                           stride=(1, 1),\n",
    "#                           padding=1),\n",
    "#                 nn.ReLU(),            \n",
    "#                 nn.Conv2d(in_channels=512,\n",
    "#                           out_channels=512,\n",
    "#                           kernel_size=(3, 3),\n",
    "#                           stride=(1, 1),\n",
    "#                           padding=1),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Conv2d(in_channels=512,\n",
    "#                           out_channels=512,\n",
    "#                           kernel_size=(3, 3),\n",
    "#                           stride=(1, 1),\n",
    "#                           padding=1),\n",
    "#                 nn.ReLU(),   \n",
    "#                 nn.MaxPool2d(kernel_size=(2, 2),\n",
    "#                              stride=(2, 2))             \n",
    "#         )\n",
    "        \n",
    "#         self.classifier = nn.Sequential(\n",
    "#                 nn.Linear(512*2*2, 4096),\n",
    "#                 nn.ReLU(),   \n",
    "#                 nn.Linear(4096, 4096),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Linear(4096, num_classes)\n",
    "#         )\n",
    "#         for m in self.modules():\n",
    "#             if isinstance(m, torch.nn.Conv2d):\n",
    "#                 #n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "#                 #m.weight.data.normal_(0, np.sqrt(2. / n))\n",
    "#                 m.weight.detach().normal_(0, 0.05)\n",
    "#                 if m.bias is not None:\n",
    "#                     m.bias.detach().zero_()\n",
    "#             elif isinstance(m, torch.nn.Linear):\n",
    "#                 m.weight.detach().normal_(0, 0.05)\n",
    "#                 m.bias.detach().detach().zero_()\n",
    "        \n",
    "#     def forward(self, x):\n",
    "\n",
    "#         x = self.block_1(x)\n",
    "#         x = self.block_2(x)\n",
    "#         x = self.block_3(x)\n",
    "#         x = self.block_4(x)\n",
    "#         x = self.block_5(x)\n",
    "\n",
    "#         logits = self.classifier(x.view(-1, 512*2*2))\n",
    "#         pred = F.softmax(logits, dim=1)\n",
    "\n",
    "#         return logits,pred\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(NN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(32*32,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,num_classes),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        pred = F.softmax(logits, dim=1)\n",
    "\n",
    "        return logits,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(model, epochs, train_loader, optimizer, loss_fn, train_loss_list, train_acc_list, device):\n",
    "#     size = len(train_loader.dataset)\n",
    "#     # loss_fn = nn.CrossEntropyLoss()\n",
    "#     # optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "#     for epoch in range(epochs):\n",
    "#         correct = 0\n",
    "#         model.train()\n",
    "#         print(f'Epoch {epoch+1}\\n-------------------------------')\n",
    "#         for i, (x, y) in enumerate(train_loader):\n",
    "#             optimizer.zero_grad()\n",
    "#             x, y = x.to(device), y.to(device)\n",
    "#             logits, pred = model.forward(x)\n",
    "#             y_pred = pred.argmax(dim=1)\n",
    "#             loss = loss_fn(y_pred, y)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             if (i+1) % 16 == 0:\n",
    "#                 loss, current = loss.item(), (i+1) * len(x)\n",
    "#                 print(f'Loss: {loss:>7f}  [{current:>5d}/{size:>5d}]')\n",
    "\n",
    "def train_loop(model, train_loader, optimizer, loss_fn, train_loss_list, train_acc_list, device):\n",
    "    size = len(train_loader.dataset)\n",
    "    # loss_fn = nn.CrossEntropyLoss()\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    train_loss, correct = 0, 0\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        # print(x.shape)\n",
    "        # print(y.shape)\n",
    "        logits, pred = model.forward(x)\n",
    "        # print(pred.shape)\n",
    "        y_pred = pred.argmax(dim=1)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        correct += (y_pred == y).type(torch.float).sum().item()\n",
    "        if (i+1) % 16 == 0:\n",
    "            loss, current = loss.item(), (i+1) * len(x)\n",
    "            print(f'Loss: {loss:>7f}  [{current:>5d}/{size:>5d}]')\n",
    "    train_loss /= size\n",
    "    correct /= size\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc_list.append(correct)\n",
    "\n",
    "def test_loop(model, test_loader, loss_fn, device, test_loss_list, test_acc_list):\n",
    "    size = len(test_loader.dataset)\n",
    "    test_loss, correct = 0,0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x,y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits, pred = model.forward(x)\n",
    "            y_pred = pred.argmax(dim=1)\n",
    "\n",
    "            test_loss += loss_fn(pred,y).item()\n",
    "            correct += (y_pred == y).type(torch.float).sum().item()\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "\n",
    "    test_loss_list.append(test_loss)\n",
    "    test_acc_list.append(correct)\n",
    "\n",
    "    print(f'Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]]), 9)\n",
      "torch.Size([1, 32, 32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Loss: 2.287584  [ 1024/60000]\n",
      "Loss: 2.228179  [ 2048/60000]\n",
      "Loss: 2.161647  [ 3072/60000]\n",
      "Loss: 2.007958  [ 4096/60000]\n",
      "Loss: 2.058382  [ 5120/60000]\n",
      "Loss: 1.908834  [ 6144/60000]\n",
      "Loss: 2.029009  [ 7168/60000]\n",
      "Loss: 1.908130  [ 8192/60000]\n",
      "Loss: 1.949721  [ 9216/60000]\n",
      "Loss: 1.846420  [10240/60000]\n",
      "Loss: 1.898970  [11264/60000]\n",
      "Loss: 1.888623  [12288/60000]\n",
      "Loss: 1.967271  [13312/60000]\n",
      "Loss: 1.946810  [14336/60000]\n",
      "Loss: 1.898569  [15360/60000]\n",
      "Loss: 1.923032  [16384/60000]\n",
      "Loss: 1.872748  [17408/60000]\n",
      "Loss: 1.956013  [18432/60000]\n",
      "Loss: 1.903431  [19456/60000]\n",
      "Loss: 1.929452  [20480/60000]\n",
      "Loss: 1.933716  [21504/60000]\n",
      "Loss: 1.797627  [22528/60000]\n",
      "Loss: 1.889303  [23552/60000]\n",
      "Loss: 1.864167  [24576/60000]\n",
      "Loss: 1.897095  [25600/60000]\n",
      "Loss: 1.929738  [26624/60000]\n",
      "Loss: 1.880060  [27648/60000]\n",
      "Loss: 1.864867  [28672/60000]\n",
      "Loss: 1.863871  [29696/60000]\n",
      "Loss: 1.836507  [30720/60000]\n",
      "Loss: 1.864525  [31744/60000]\n",
      "Loss: 1.985689  [32768/60000]\n",
      "Loss: 1.896611  [33792/60000]\n",
      "Loss: 1.983002  [34816/60000]\n",
      "Loss: 1.961083  [35840/60000]\n",
      "Loss: 1.847705  [36864/60000]\n",
      "Loss: 1.813173  [37888/60000]\n",
      "Loss: 1.857215  [38912/60000]\n",
      "Loss: 1.970130  [39936/60000]\n",
      "Loss: 1.877954  [40960/60000]\n",
      "Loss: 1.959439  [41984/60000]\n",
      "Loss: 1.863305  [43008/60000]\n",
      "Loss: 1.837420  [44032/60000]\n",
      "Loss: 1.997964  [45056/60000]\n",
      "Loss: 1.839646  [46080/60000]\n",
      "Loss: 1.903454  [47104/60000]\n",
      "Loss: 1.855287  [48128/60000]\n",
      "Loss: 1.876574  [49152/60000]\n",
      "Loss: 1.960333  [50176/60000]\n",
      "Loss: 1.899342  [51200/60000]\n",
      "Loss: 1.883579  [52224/60000]\n",
      "Loss: 1.781435  [53248/60000]\n",
      "Loss: 1.879563  [54272/60000]\n",
      "Loss: 1.919700  [55296/60000]\n",
      "Loss: 1.827772  [56320/60000]\n",
      "Loss: 1.969545  [57344/60000]\n",
      "Loss: 1.917485  [58368/60000]\n",
      "Loss: 1.847814  [59392/60000]\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 0.029535 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Loss: 1.912310  [ 1024/60000]\n",
      "Loss: 1.885466  [ 2048/60000]\n",
      "Loss: 1.893245  [ 3072/60000]\n",
      "Loss: 1.900289  [ 4096/60000]\n",
      "Loss: 1.818237  [ 5120/60000]\n",
      "Loss: 1.835615  [ 6144/60000]\n",
      "Loss: 1.859042  [ 7168/60000]\n",
      "Loss: 1.839068  [ 8192/60000]\n",
      "Loss: 1.877550  [ 9216/60000]\n",
      "Loss: 1.924532  [10240/60000]\n",
      "Loss: 1.883454  [11264/60000]\n",
      "Loss: 1.843584  [12288/60000]\n",
      "Loss: 1.919143  [13312/60000]\n",
      "Loss: 1.879276  [14336/60000]\n",
      "Loss: 1.905079  [15360/60000]\n",
      "Loss: 1.822676  [16384/60000]\n",
      "Loss: 1.811041  [17408/60000]\n",
      "Loss: 1.871403  [18432/60000]\n",
      "Loss: 2.001054  [19456/60000]\n",
      "Loss: 1.907761  [20480/60000]\n",
      "Loss: 1.823870  [21504/60000]\n",
      "Loss: 1.887039  [22528/60000]\n",
      "Loss: 1.867573  [23552/60000]\n",
      "Loss: 1.872545  [24576/60000]\n",
      "Loss: 1.853180  [25600/60000]\n",
      "Loss: 1.908294  [26624/60000]\n",
      "Loss: 1.804255  [27648/60000]\n",
      "Loss: 1.906996  [28672/60000]\n",
      "Loss: 1.847057  [29696/60000]\n",
      "Loss: 1.962350  [30720/60000]\n",
      "Loss: 1.883393  [31744/60000]\n",
      "Loss: 1.871246  [32768/60000]\n",
      "Loss: 1.984408  [33792/60000]\n",
      "Loss: 1.891194  [34816/60000]\n",
      "Loss: 1.874667  [35840/60000]\n",
      "Loss: 1.861469  [36864/60000]\n",
      "Loss: 1.846520  [37888/60000]\n",
      "Loss: 1.999012  [38912/60000]\n",
      "Loss: 1.871542  [39936/60000]\n",
      "Loss: 1.880864  [40960/60000]\n",
      "Loss: 1.892802  [41984/60000]\n",
      "Loss: 1.860229  [43008/60000]\n",
      "Loss: 1.854683  [44032/60000]\n",
      "Loss: 1.939125  [45056/60000]\n",
      "Loss: 1.845344  [46080/60000]\n",
      "Loss: 1.835938  [47104/60000]\n",
      "Loss: 1.879210  [48128/60000]\n",
      "Loss: 1.891221  [49152/60000]\n",
      "Loss: 1.883500  [50176/60000]\n",
      "Loss: 1.885440  [51200/60000]\n",
      "Loss: 1.840784  [52224/60000]\n",
      "Loss: 1.803590  [53248/60000]\n",
      "Loss: 1.824253  [54272/60000]\n",
      "Loss: 1.827576  [55296/60000]\n",
      "Loss: 1.779345  [56320/60000]\n",
      "Loss: 1.907948  [57344/60000]\n",
      "Loss: 1.789540  [58368/60000]\n",
      "Loss: 1.860139  [59392/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 0.029433 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Loss: 1.907024  [ 1024/60000]\n",
      "Loss: 1.898023  [ 2048/60000]\n",
      "Loss: 1.822038  [ 3072/60000]\n",
      "Loss: 1.843126  [ 4096/60000]\n",
      "Loss: 1.893989  [ 5120/60000]\n",
      "Loss: 1.750255  [ 6144/60000]\n",
      "Loss: 1.912577  [ 7168/60000]\n",
      "Loss: 1.922650  [ 8192/60000]\n",
      "Loss: 1.774612  [ 9216/60000]\n",
      "Loss: 1.903588  [10240/60000]\n",
      "Loss: 1.863331  [11264/60000]\n",
      "Loss: 1.963095  [12288/60000]\n",
      "Loss: 1.836364  [13312/60000]\n",
      "Loss: 1.860471  [14336/60000]\n",
      "Loss: 1.829552  [15360/60000]\n",
      "Loss: 1.868805  [16384/60000]\n",
      "Loss: 1.915847  [17408/60000]\n",
      "Loss: 1.893473  [18432/60000]\n",
      "Loss: 1.891143  [19456/60000]\n",
      "Loss: 1.848980  [20480/60000]\n",
      "Loss: 1.871925  [21504/60000]\n",
      "Loss: 1.840916  [22528/60000]\n",
      "Loss: 1.884160  [23552/60000]\n",
      "Loss: 1.902773  [24576/60000]\n",
      "Loss: 1.974485  [25600/60000]\n",
      "Loss: 1.860647  [26624/60000]\n",
      "Loss: 1.849736  [27648/60000]\n",
      "Loss: 1.837959  [28672/60000]\n",
      "Loss: 1.772646  [29696/60000]\n",
      "Loss: 1.912470  [30720/60000]\n",
      "Loss: 1.887984  [31744/60000]\n",
      "Loss: 1.869612  [32768/60000]\n",
      "Loss: 1.906129  [33792/60000]\n",
      "Loss: 1.834430  [34816/60000]\n",
      "Loss: 1.773643  [35840/60000]\n",
      "Loss: 1.810101  [36864/60000]\n",
      "Loss: 1.822595  [37888/60000]\n",
      "Loss: 1.947016  [38912/60000]\n",
      "Loss: 1.830902  [39936/60000]\n",
      "Loss: 1.860500  [40960/60000]\n",
      "Loss: 1.940349  [41984/60000]\n",
      "Loss: 1.935881  [43008/60000]\n",
      "Loss: 1.900257  [44032/60000]\n",
      "Loss: 1.859436  [45056/60000]\n",
      "Loss: 1.830207  [46080/60000]\n",
      "Loss: 1.842057  [47104/60000]\n",
      "Loss: 1.885231  [48128/60000]\n",
      "Loss: 1.934076  [49152/60000]\n",
      "Loss: 1.928892  [50176/60000]\n",
      "Loss: 1.958537  [51200/60000]\n",
      "Loss: 1.871249  [52224/60000]\n",
      "Loss: 2.018016  [53248/60000]\n",
      "Loss: 1.832728  [54272/60000]\n",
      "Loss: 1.899349  [55296/60000]\n",
      "Loss: 1.830462  [56320/60000]\n",
      "Loss: 1.915707  [57344/60000]\n",
      "Loss: 1.859938  [58368/60000]\n",
      "Loss: 1.886552  [59392/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 0.029390 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Loss: 1.844012  [ 1024/60000]\n",
      "Loss: 1.901564  [ 2048/60000]\n",
      "Loss: 1.854561  [ 3072/60000]\n",
      "Loss: 1.826133  [ 4096/60000]\n",
      "Loss: 1.884803  [ 5120/60000]\n",
      "Loss: 1.916378  [ 6144/60000]\n",
      "Loss: 1.759115  [ 7168/60000]\n",
      "Loss: 1.825531  [ 8192/60000]\n",
      "Loss: 1.841140  [ 9216/60000]\n",
      "Loss: 1.812849  [10240/60000]\n",
      "Loss: 1.793764  [11264/60000]\n",
      "Loss: 1.881833  [12288/60000]\n",
      "Loss: 1.881648  [13312/60000]\n",
      "Loss: 1.833704  [14336/60000]\n",
      "Loss: 1.872794  [15360/60000]\n",
      "Loss: 1.798028  [16384/60000]\n",
      "Loss: 1.816225  [17408/60000]\n",
      "Loss: 1.823988  [18432/60000]\n",
      "Loss: 1.908061  [19456/60000]\n",
      "Loss: 1.891010  [20480/60000]\n",
      "Loss: 1.727469  [21504/60000]\n",
      "Loss: 1.876619  [22528/60000]\n",
      "Loss: 1.839422  [23552/60000]\n",
      "Loss: 1.901628  [24576/60000]\n",
      "Loss: 1.827142  [25600/60000]\n",
      "Loss: 1.792235  [26624/60000]\n",
      "Loss: 1.884048  [27648/60000]\n",
      "Loss: 1.819406  [28672/60000]\n",
      "Loss: 1.852500  [29696/60000]\n",
      "Loss: 1.928572  [30720/60000]\n",
      "Loss: 1.744417  [31744/60000]\n",
      "Loss: 1.879839  [32768/60000]\n",
      "Loss: 1.881219  [33792/60000]\n",
      "Loss: 1.815153  [34816/60000]\n",
      "Loss: 1.819565  [35840/60000]\n",
      "Loss: 1.799873  [36864/60000]\n",
      "Loss: 1.854574  [37888/60000]\n",
      "Loss: 1.916651  [38912/60000]\n",
      "Loss: 1.730838  [39936/60000]\n",
      "Loss: 1.827466  [40960/60000]\n",
      "Loss: 1.869802  [41984/60000]\n",
      "Loss: 1.736575  [43008/60000]\n",
      "Loss: 1.937764  [44032/60000]\n",
      "Loss: 1.934945  [45056/60000]\n",
      "Loss: 1.842610  [46080/60000]\n",
      "Loss: 1.894119  [47104/60000]\n",
      "Loss: 1.837410  [48128/60000]\n",
      "Loss: 1.792120  [49152/60000]\n",
      "Loss: 1.770655  [50176/60000]\n",
      "Loss: 1.887988  [51200/60000]\n",
      "Loss: 1.756214  [52224/60000]\n",
      "Loss: 1.837101  [53248/60000]\n",
      "Loss: 1.867670  [54272/60000]\n",
      "Loss: 1.838855  [55296/60000]\n",
      "Loss: 2.031162  [56320/60000]\n",
      "Loss: 1.933447  [57344/60000]\n",
      "Loss: 1.903973  [58368/60000]\n",
      "Loss: 1.756287  [59392/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 0.029395 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Loss: 1.789633  [ 1024/60000]\n",
      "Loss: 1.814946  [ 2048/60000]\n",
      "Loss: 1.943055  [ 3072/60000]\n",
      "Loss: 1.844233  [ 4096/60000]\n",
      "Loss: 1.828647  [ 5120/60000]\n",
      "Loss: 1.900663  [ 6144/60000]\n",
      "Loss: 1.930468  [ 7168/60000]\n",
      "Loss: 1.813363  [ 8192/60000]\n",
      "Loss: 1.839725  [ 9216/60000]\n",
      "Loss: 1.919571  [10240/60000]\n",
      "Loss: 1.858981  [11264/60000]\n",
      "Loss: 1.901351  [12288/60000]\n",
      "Loss: 1.819780  [13312/60000]\n",
      "Loss: 1.852684  [14336/60000]\n",
      "Loss: 1.910460  [15360/60000]\n",
      "Loss: 1.791129  [16384/60000]\n",
      "Loss: 1.878870  [17408/60000]\n",
      "Loss: 1.941342  [18432/60000]\n",
      "Loss: 1.878228  [19456/60000]\n",
      "Loss: 1.877822  [20480/60000]\n",
      "Loss: 1.775846  [21504/60000]\n",
      "Loss: 1.955337  [22528/60000]\n",
      "Loss: 1.985751  [23552/60000]\n",
      "Loss: 1.849989  [24576/60000]\n",
      "Loss: 1.877484  [25600/60000]\n",
      "Loss: 1.786792  [26624/60000]\n",
      "Loss: 1.740548  [27648/60000]\n",
      "Loss: 1.898511  [28672/60000]\n",
      "Loss: 1.809570  [29696/60000]\n",
      "Loss: 1.810615  [30720/60000]\n",
      "Loss: 1.892317  [31744/60000]\n",
      "Loss: 1.818775  [32768/60000]\n",
      "Loss: 1.894000  [33792/60000]\n",
      "Loss: 1.777287  [34816/60000]\n",
      "Loss: 1.856064  [35840/60000]\n",
      "Loss: 1.739558  [36864/60000]\n",
      "Loss: 1.808874  [37888/60000]\n",
      "Loss: 1.859540  [38912/60000]\n",
      "Loss: 1.903849  [39936/60000]\n",
      "Loss: 1.856332  [40960/60000]\n",
      "Loss: 1.806013  [41984/60000]\n",
      "Loss: 1.734414  [43008/60000]\n",
      "Loss: 1.822392  [44032/60000]\n",
      "Loss: 1.940650  [45056/60000]\n",
      "Loss: 1.835508  [46080/60000]\n",
      "Loss: 1.942109  [47104/60000]\n",
      "Loss: 1.867052  [48128/60000]\n",
      "Loss: 1.841343  [49152/60000]\n",
      "Loss: 1.921738  [50176/60000]\n",
      "Loss: 1.902693  [51200/60000]\n",
      "Loss: 1.851713  [52224/60000]\n",
      "Loss: 1.931407  [53248/60000]\n",
      "Loss: 1.773833  [54272/60000]\n",
      "Loss: 1.927930  [55296/60000]\n",
      "Loss: 1.866221  [56320/60000]\n",
      "Loss: 1.890874  [57344/60000]\n",
      "Loss: 1.929872  [58368/60000]\n",
      "Loss: 1.931983  [59392/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.5%, Avg loss: 0.029333 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Loss: 1.875476  [ 1024/60000]\n",
      "Loss: 1.838396  [ 2048/60000]\n",
      "Loss: 1.854141  [ 3072/60000]\n",
      "Loss: 1.943672  [ 4096/60000]\n",
      "Loss: 1.867547  [ 5120/60000]\n",
      "Loss: 1.838670  [ 6144/60000]\n",
      "Loss: 1.774418  [ 7168/60000]\n",
      "Loss: 1.872474  [ 8192/60000]\n",
      "Loss: 1.846839  [ 9216/60000]\n",
      "Loss: 2.003896  [10240/60000]\n",
      "Loss: 1.945668  [11264/60000]\n",
      "Loss: 1.862318  [12288/60000]\n",
      "Loss: 1.816925  [13312/60000]\n",
      "Loss: 1.866016  [14336/60000]\n",
      "Loss: 1.771172  [15360/60000]\n",
      "Loss: 1.857588  [16384/60000]\n",
      "Loss: 1.874943  [17408/60000]\n",
      "Loss: 1.886002  [18432/60000]\n",
      "Loss: 1.846427  [19456/60000]\n",
      "Loss: 1.826007  [20480/60000]\n",
      "Loss: 1.839042  [21504/60000]\n",
      "Loss: 1.759692  [22528/60000]\n",
      "Loss: 1.880544  [23552/60000]\n",
      "Loss: 1.874272  [24576/60000]\n",
      "Loss: 1.763601  [25600/60000]\n",
      "Loss: 1.944920  [26624/60000]\n",
      "Loss: 1.735757  [27648/60000]\n",
      "Loss: 1.902362  [28672/60000]\n",
      "Loss: 1.742405  [29696/60000]\n",
      "Loss: 1.829162  [30720/60000]\n",
      "Loss: 1.881056  [31744/60000]\n",
      "Loss: 1.822093  [32768/60000]\n",
      "Loss: 1.993356  [33792/60000]\n",
      "Loss: 1.794635  [34816/60000]\n",
      "Loss: 1.875473  [35840/60000]\n",
      "Loss: 1.852187  [36864/60000]\n",
      "Loss: 1.936998  [37888/60000]\n",
      "Loss: 1.752532  [38912/60000]\n",
      "Loss: 1.843920  [39936/60000]\n",
      "Loss: 1.795253  [40960/60000]\n",
      "Loss: 1.908113  [41984/60000]\n",
      "Loss: 1.871626  [43008/60000]\n",
      "Loss: 1.812937  [44032/60000]\n",
      "Loss: 1.814075  [45056/60000]\n",
      "Loss: 1.949424  [46080/60000]\n",
      "Loss: 1.795918  [47104/60000]\n",
      "Loss: 1.860678  [48128/60000]\n",
      "Loss: 1.830945  [49152/60000]\n",
      "Loss: 1.796139  [50176/60000]\n",
      "Loss: 1.840334  [51200/60000]\n",
      "Loss: 1.897347  [52224/60000]\n",
      "Loss: 1.882234  [53248/60000]\n",
      "Loss: 1.930578  [54272/60000]\n",
      "Loss: 1.837809  [55296/60000]\n",
      "Loss: 1.811590  [56320/60000]\n",
      "Loss: 1.857633  [57344/60000]\n",
      "Loss: 1.722196  [58368/60000]\n",
      "Loss: 1.884258  [59392/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 0.029286 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Loss: 1.887197  [ 1024/60000]\n",
      "Loss: 1.853812  [ 2048/60000]\n",
      "Loss: 1.901155  [ 3072/60000]\n",
      "Loss: 1.911964  [ 4096/60000]\n",
      "Loss: 1.809856  [ 5120/60000]\n",
      "Loss: 1.836959  [ 6144/60000]\n",
      "Loss: 1.860472  [ 7168/60000]\n",
      "Loss: 1.832708  [ 8192/60000]\n",
      "Loss: 1.790694  [ 9216/60000]\n",
      "Loss: 1.921343  [10240/60000]\n",
      "Loss: 1.753543  [11264/60000]\n",
      "Loss: 1.847594  [12288/60000]\n",
      "Loss: 1.881998  [13312/60000]\n",
      "Loss: 1.847762  [14336/60000]\n",
      "Loss: 1.869505  [15360/60000]\n",
      "Loss: 1.801395  [16384/60000]\n",
      "Loss: 1.803651  [17408/60000]\n",
      "Loss: 1.944784  [18432/60000]\n",
      "Loss: 1.875090  [19456/60000]\n",
      "Loss: 1.823890  [20480/60000]\n",
      "Loss: 1.958435  [21504/60000]\n",
      "Loss: 1.809921  [22528/60000]\n",
      "Loss: 1.826925  [23552/60000]\n",
      "Loss: 1.892838  [24576/60000]\n",
      "Loss: 1.804638  [25600/60000]\n",
      "Loss: 1.975078  [26624/60000]\n",
      "Loss: 1.821719  [27648/60000]\n",
      "Loss: 1.735542  [28672/60000]\n",
      "Loss: 1.855192  [29696/60000]\n",
      "Loss: 1.888828  [30720/60000]\n",
      "Loss: 1.781831  [31744/60000]\n",
      "Loss: 1.947302  [32768/60000]\n",
      "Loss: 1.861654  [33792/60000]\n",
      "Loss: 1.896567  [34816/60000]\n",
      "Loss: 1.772882  [35840/60000]\n",
      "Loss: 1.957070  [36864/60000]\n",
      "Loss: 1.862756  [37888/60000]\n",
      "Loss: 1.807068  [38912/60000]\n",
      "Loss: 1.977668  [39936/60000]\n",
      "Loss: 1.857308  [40960/60000]\n",
      "Loss: 1.821853  [41984/60000]\n",
      "Loss: 1.813271  [43008/60000]\n",
      "Loss: 1.859795  [44032/60000]\n",
      "Loss: 1.941576  [45056/60000]\n",
      "Loss: 1.893543  [46080/60000]\n",
      "Loss: 1.857502  [47104/60000]\n",
      "Loss: 1.786094  [48128/60000]\n",
      "Loss: 1.828176  [49152/60000]\n",
      "Loss: 1.785353  [50176/60000]\n",
      "Loss: 1.794160  [51200/60000]\n",
      "Loss: 1.739812  [52224/60000]\n",
      "Loss: 1.890590  [53248/60000]\n",
      "Loss: 1.885776  [54272/60000]\n",
      "Loss: 1.857799  [55296/60000]\n",
      "Loss: 1.759795  [56320/60000]\n",
      "Loss: 1.818444  [57344/60000]\n",
      "Loss: 1.898590  [58368/60000]\n",
      "Loss: 1.837837  [59392/60000]\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.029267 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Loss: 1.815290  [ 1024/60000]\n",
      "Loss: 1.822350  [ 2048/60000]\n",
      "Loss: 1.919872  [ 3072/60000]\n",
      "Loss: 1.748161  [ 4096/60000]\n",
      "Loss: 1.868703  [ 5120/60000]\n",
      "Loss: 1.886533  [ 6144/60000]\n",
      "Loss: 1.950016  [ 7168/60000]\n",
      "Loss: 1.754014  [ 8192/60000]\n",
      "Loss: 1.851802  [ 9216/60000]\n",
      "Loss: 1.843871  [10240/60000]\n",
      "Loss: 1.850388  [11264/60000]\n",
      "Loss: 1.852074  [12288/60000]\n",
      "Loss: 1.775914  [13312/60000]\n",
      "Loss: 1.859622  [14336/60000]\n",
      "Loss: 1.801435  [15360/60000]\n",
      "Loss: 1.828219  [16384/60000]\n",
      "Loss: 1.916567  [17408/60000]\n",
      "Loss: 1.820123  [18432/60000]\n",
      "Loss: 1.825907  [19456/60000]\n",
      "Loss: 1.788481  [20480/60000]\n",
      "Loss: 1.868651  [21504/60000]\n",
      "Loss: 1.911662  [22528/60000]\n",
      "Loss: 1.806080  [23552/60000]\n",
      "Loss: 1.833784  [24576/60000]\n",
      "Loss: 1.905426  [25600/60000]\n",
      "Loss: 1.848366  [26624/60000]\n",
      "Loss: 1.889094  [27648/60000]\n",
      "Loss: 1.919531  [28672/60000]\n",
      "Loss: 1.877026  [29696/60000]\n",
      "Loss: 1.769281  [30720/60000]\n",
      "Loss: 1.898717  [31744/60000]\n",
      "Loss: 1.850099  [32768/60000]\n",
      "Loss: 1.844589  [33792/60000]\n",
      "Loss: 1.946300  [34816/60000]\n",
      "Loss: 1.860140  [35840/60000]\n",
      "Loss: 1.792424  [36864/60000]\n",
      "Loss: 1.836437  [37888/60000]\n",
      "Loss: 1.790672  [38912/60000]\n",
      "Loss: 1.829911  [39936/60000]\n",
      "Loss: 1.831974  [40960/60000]\n",
      "Loss: 1.921716  [41984/60000]\n",
      "Loss: 1.794038  [43008/60000]\n",
      "Loss: 1.714109  [44032/60000]\n",
      "Loss: 1.898002  [45056/60000]\n",
      "Loss: 1.867208  [46080/60000]\n",
      "Loss: 1.864168  [47104/60000]\n",
      "Loss: 1.809757  [48128/60000]\n",
      "Loss: 1.838810  [49152/60000]\n",
      "Loss: 1.872771  [50176/60000]\n",
      "Loss: 1.917292  [51200/60000]\n",
      "Loss: 1.920676  [52224/60000]\n",
      "Loss: 1.885352  [53248/60000]\n",
      "Loss: 1.761157  [54272/60000]\n",
      "Loss: 1.866413  [55296/60000]\n",
      "Loss: 1.820466  [56320/60000]\n",
      "Loss: 1.854071  [57344/60000]\n",
      "Loss: 1.870015  [58368/60000]\n",
      "Loss: 1.815774  [59392/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.5%, Avg loss: 0.029173 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Loss: 1.829352  [ 1024/60000]\n",
      "Loss: 1.734783  [ 2048/60000]\n",
      "Loss: 1.954102  [ 3072/60000]\n",
      "Loss: 1.867825  [ 4096/60000]\n",
      "Loss: 1.851747  [ 5120/60000]\n",
      "Loss: 1.929698  [ 6144/60000]\n",
      "Loss: 1.830504  [ 7168/60000]\n",
      "Loss: 1.921907  [ 8192/60000]\n",
      "Loss: 1.966377  [ 9216/60000]\n",
      "Loss: 1.911150  [10240/60000]\n",
      "Loss: 1.881982  [11264/60000]\n",
      "Loss: 1.854848  [12288/60000]\n",
      "Loss: 1.735658  [13312/60000]\n",
      "Loss: 1.885951  [14336/60000]\n",
      "Loss: 1.956219  [15360/60000]\n",
      "Loss: 1.819456  [16384/60000]\n",
      "Loss: 1.828299  [17408/60000]\n",
      "Loss: 1.851802  [18432/60000]\n",
      "Loss: 1.819520  [19456/60000]\n",
      "Loss: 1.855514  [20480/60000]\n",
      "Loss: 1.880617  [21504/60000]\n",
      "Loss: 1.927763  [22528/60000]\n",
      "Loss: 1.793784  [23552/60000]\n",
      "Loss: 1.959311  [24576/60000]\n",
      "Loss: 1.819974  [25600/60000]\n",
      "Loss: 1.897630  [26624/60000]\n",
      "Loss: 1.790682  [27648/60000]\n",
      "Loss: 1.797087  [28672/60000]\n",
      "Loss: 1.789657  [29696/60000]\n",
      "Loss: 1.890707  [30720/60000]\n",
      "Loss: 1.805095  [31744/60000]\n",
      "Loss: 1.761169  [32768/60000]\n",
      "Loss: 1.846895  [33792/60000]\n",
      "Loss: 1.832565  [34816/60000]\n",
      "Loss: 1.861291  [35840/60000]\n",
      "Loss: 1.946056  [36864/60000]\n",
      "Loss: 1.746991  [37888/60000]\n",
      "Loss: 1.901069  [38912/60000]\n",
      "Loss: 1.835487  [39936/60000]\n",
      "Loss: 1.837827  [40960/60000]\n",
      "Loss: 1.947764  [41984/60000]\n",
      "Loss: 1.807160  [43008/60000]\n",
      "Loss: 1.895006  [44032/60000]\n",
      "Loss: 1.858736  [45056/60000]\n",
      "Loss: 1.825253  [46080/60000]\n",
      "Loss: 1.949508  [47104/60000]\n",
      "Loss: 1.880127  [48128/60000]\n",
      "Loss: 1.863292  [49152/60000]\n",
      "Loss: 1.783185  [50176/60000]\n",
      "Loss: 1.824197  [51200/60000]\n",
      "Loss: 1.827221  [52224/60000]\n",
      "Loss: 1.863814  [53248/60000]\n",
      "Loss: 1.739790  [54272/60000]\n",
      "Loss: 1.823042  [55296/60000]\n",
      "Loss: 1.808192  [56320/60000]\n",
      "Loss: 1.724984  [57344/60000]\n",
      "Loss: 1.806714  [58368/60000]\n",
      "Loss: 1.857878  [59392/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 0.029136 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Loss: 1.777091  [ 1024/60000]\n",
      "Loss: 1.779237  [ 2048/60000]\n",
      "Loss: 1.917704  [ 3072/60000]\n",
      "Loss: 1.924768  [ 4096/60000]\n",
      "Loss: 1.901860  [ 5120/60000]\n",
      "Loss: 1.891057  [ 6144/60000]\n",
      "Loss: 1.858096  [ 7168/60000]\n",
      "Loss: 1.881150  [ 8192/60000]\n",
      "Loss: 2.010047  [ 9216/60000]\n",
      "Loss: 1.771605  [10240/60000]\n",
      "Loss: 1.869560  [11264/60000]\n",
      "Loss: 1.890949  [12288/60000]\n",
      "Loss: 1.935058  [13312/60000]\n",
      "Loss: 1.839033  [14336/60000]\n",
      "Loss: 1.824952  [15360/60000]\n",
      "Loss: 1.836713  [16384/60000]\n",
      "Loss: 1.807143  [17408/60000]\n",
      "Loss: 1.856178  [18432/60000]\n",
      "Loss: 1.813816  [19456/60000]\n",
      "Loss: 1.749089  [20480/60000]\n",
      "Loss: 1.815752  [21504/60000]\n",
      "Loss: 1.869343  [22528/60000]\n",
      "Loss: 1.817187  [23552/60000]\n",
      "Loss: 1.872981  [24576/60000]\n",
      "Loss: 1.855878  [25600/60000]\n",
      "Loss: 1.795365  [26624/60000]\n",
      "Loss: 1.915497  [27648/60000]\n",
      "Loss: 2.012026  [28672/60000]\n",
      "Loss: 1.841610  [29696/60000]\n",
      "Loss: 1.832226  [30720/60000]\n",
      "Loss: 1.917684  [31744/60000]\n",
      "Loss: 1.887654  [32768/60000]\n",
      "Loss: 1.821769  [33792/60000]\n",
      "Loss: 1.835256  [34816/60000]\n",
      "Loss: 1.821727  [35840/60000]\n",
      "Loss: 1.830737  [36864/60000]\n",
      "Loss: 1.841760  [37888/60000]\n",
      "Loss: 1.830526  [38912/60000]\n",
      "Loss: 1.851262  [39936/60000]\n",
      "Loss: 1.906449  [40960/60000]\n",
      "Loss: 1.846972  [41984/60000]\n",
      "Loss: 1.821100  [43008/60000]\n",
      "Loss: 1.938617  [44032/60000]\n",
      "Loss: 1.842801  [45056/60000]\n",
      "Loss: 1.771468  [46080/60000]\n",
      "Loss: 1.832183  [47104/60000]\n",
      "Loss: 1.838941  [48128/60000]\n",
      "Loss: 1.827603  [49152/60000]\n",
      "Loss: 1.766726  [50176/60000]\n",
      "Loss: 1.824009  [51200/60000]\n",
      "Loss: 1.933854  [52224/60000]\n",
      "Loss: 1.887789  [53248/60000]\n",
      "Loss: 1.783320  [54272/60000]\n",
      "Loss: 1.887485  [55296/60000]\n",
      "Loss: 1.765700  [56320/60000]\n",
      "Loss: 1.814871  [57344/60000]\n",
      "Loss: 1.781948  [58368/60000]\n",
      "Loss: 1.858216  [59392/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 0.029102 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(3312)\n",
    "args = {\n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'batch_size': 64,\n",
    "    'test_batch_size': 1000,\n",
    "    'epochs': 10,\n",
    "    'lr': 1e-4\n",
    "}\n",
    "\n",
    "model = NN(num_classes=10)\n",
    "model = model.to(args['device'])\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=args['lr'])\n",
    "\n",
    "# trans = [transforms.ToTensor()]\n",
    "# trans.insert(0, transforms.Resize(32))\n",
    "# trans = transforms.Compose(trans)\n",
    "trans = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root='./dataset', train=True,\n",
    "                                      transform=trans, download=True)\n",
    "test_dataset = datasets.FashionMNIST(root='./dataset', train=False,\n",
    "                                     transform=trans, download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=args[\"batch_size\"], shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=args[\"batch_size\"], shuffle=True)\n",
    "\n",
    "\n",
    "labels_map = {\n",
    "    0:\"T_shirt\",\n",
    "    1:\"Trouser\",\n",
    "    2:\"Pullover\",\n",
    "    3:\"Dress\",\n",
    "    4:\"Coat\",\n",
    "    5:\"Sandal\",\n",
    "    6:\"Shirt\",\n",
    "    7:\"Sneaker\",\n",
    "    8:\"Bag\",\n",
    "    9:\"Ankle Boot\",\n",
    "}\n",
    "\n",
    "print(train_dataset[0])\n",
    "print(train_dataset[0][0].shape)\n",
    "figure = plt.figure(figsize=(8,8))\n",
    "cols, rows = 3,3\n",
    "for i in range(1,cols*rows+1):\n",
    "    sample_idx = torch.randint(len(train_dataset),size=(1,)).item()\n",
    "    img,label = train_dataset[sample_idx]\n",
    "    figure.add_subplot(rows,cols,i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img.squeeze(),cmap='gray') # squeeze() can be used to eliminate the dimension whose length is 1\n",
    "plt.show()\n",
    "\n",
    "\n",
    "train_acc_list, test_acc_list = [], []\n",
    "train_loss_list, test_loss_list = [], []\n",
    "for t in range(args['epochs']):\n",
    "    print(f'Epoch {t+1}\\n-------------------------------')\n",
    "    train_loop(model, train_loader, optimizer, loss_fn, train_loss_list, train_acc_list, args['device'])\n",
    "    test_loop(model, test_loader, loss_fn, args['device'], test_loss_list, test_acc_list)\n",
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
