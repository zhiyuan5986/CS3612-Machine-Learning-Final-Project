{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/lqa/miniconda3/envs/DataScience/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "# from utils import *\n",
    "import argparse\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(NN, self).__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = (3,3), padding=(1,1), stride=(1,1)),\n",
    "            nn.BatchNorm2d(num_features = 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = (3,3), padding=(1,1), stride=(1,1)),\n",
    "            nn.BatchNorm2d(num_features = 64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = (3,3), padding=(1,1), stride=(1,1)),\n",
    "            nn.BatchNorm2d(num_features = 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = (3,3), padding=(1,1), stride=(1,1)),\n",
    "            nn.BatchNorm2d(num_features = 128),           \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = (3,3), padding=(1,1), stride=(1,1)),\n",
    "            nn.BatchNorm2d(num_features = 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = (3,3), padding=(1,1), stride=(1,1)),\n",
    "            nn.BatchNorm2d(num_features = 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = (3,3), padding=(1,1), stride=(1,1)),\n",
    "            nn.BatchNorm2d(num_features = 256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        )\n",
    "        self.block4 = nn.Sequential(\n",
    "            nn.Linear(in_features = 256*4*4, out_features = 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features = 256, out_features = 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features = 128, out_features = 10)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.softmax = F.softmax\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.block4(x)\n",
    "        pred = self.softmax(logits, dim=1)\n",
    "\n",
    "        return logits,pred\n",
    "        \n",
    "def parse_args():\n",
    "    \"\"\"parse arguments. You can add other arguments if needed.\"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--is_train\", type=int, default=1,\n",
    "        help=\"flag to decide whether to train\")\n",
    "    parser.add_argument(\"--epochs\", type=int, default=50,\n",
    "        help=\"training epochs\")\n",
    "    parser.add_argument(\"--seed\", type=int, default=3312,\n",
    "        help=\"seed of the experiment\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=1e-4,\n",
    "        help=\"the learning rate of the optimizer\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=64,\n",
    "        help=\"the batch size training samples and test samples\")\n",
    "    args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--is_train IS_TRAIN] [--epochs EPOCHS]\n",
      "                             [--seed SEED] [--lr LR] [--batch_size BATCH_SIZE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9008 --control=9006 --hb=9005 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"15f29286-2971-40e2-bc5f-24fcac025f97\" --shell=9007 --transport=\"tcp\" --iopub=9009 --f=/home/users/lqa/.local/share/jupyter/runtime/kernel-v2-1633442NiCNi1ofO586.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/lqa/miniconda3/envs/DataScience/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3513: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "args = parse_args()\n",
    "if not os.path.exists(\"./output\"):\n",
    "    os.mkdir(\"./output\")\n",
    "if not os.path.exists(\"./checkpoints\"):\n",
    "    os.mkdir(\"./checkpoints\")\n",
    "version = \"v1\"\n",
    "output_root = f\"./output/{version}\"\n",
    "if not os.path.exists(output_root):\n",
    "    os.mkdir(output_root)\n",
    "torch.manual_seed(args.seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "trans = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "model = NN(num_classes=10)\n",
    "model.load_state_dict(torch.load(f\"./checkpoints/{version}.pt\"))\n",
    "model.eval()\n",
    "\n",
    "test_dataset = datasets.FashionMNIST(root='./dataset', train=False,\n",
    "                                    transform=trans, download=True)\n",
    "test_loader_no_shuffle = DataLoader(dataset=test_dataset,\n",
    "                        batch_size=args.batch_size, shuffle=False)\n",
    "conv_features = []\n",
    "relu_features = []\n",
    "final_features = []\n",
    "def conv_hook_forward(module, fea_in, fea_out):\n",
    "    conv_features.append(nn.Flatten()(fea_out))\n",
    "    return None\n",
    "def relu_hook_forward(module, fea_in, fea_out):\n",
    "    relu_features.append(nn.Flatten()(fea_out))\n",
    "    return None\n",
    "\n",
    "h_conv = model.block3[6].register_forward_hook(hook=conv_hook_forward)\n",
    "h_relu = model.block3[8].register_forward_hook(hook=relu_hook_forward)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x,y in test_loader_no_shuffle:\n",
    "        logits, pred = model.forward(x)\n",
    "        final_features.append(logits)\n",
    "\n",
    "conv_features = torch.cat(conv_features, dim = 0).numpy()\n",
    "relu_features = torch.cat(relu_features, dim = 0).numpy()\n",
    "final_features = torch.cat(final_features, dim = 0).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_original_pairwise_affinities(X:np.array([]), \n",
    "                                     perplexity=10):\n",
    "\n",
    "    '''\n",
    "    Function to obtain affinities matrix.\n",
    "    '''\n",
    "\n",
    "    n = len(X)\n",
    "\n",
    "    print(\"Computing Pairwise Affinities....\")\n",
    "\n",
    "    p_ij = np.zeros(shape=(n,n))\n",
    "    for i in range(0,n):\n",
    "        \n",
    "        # Equation 1 numerator\n",
    "        diff = X[i]-X\n",
    "        sigma_i = grid_search(diff, i, perplexity) # Grid Search for σ_i\n",
    "        norm = np.linalg.norm(diff, axis=1)\n",
    "        p_ij[i,:] = np.exp(-norm**2/(2*sigma_i**2))\n",
    "\n",
    "        # Set p = 0 when j = i\n",
    "        np.fill_diagonal(p_ij, 0)\n",
    "        \n",
    "        # Equation 1 \n",
    "        p_ij[i,:] = p_ij[i,:]/np.sum(p_ij[i,:])\n",
    "\n",
    "    # Set 0 values to minimum numpy value (ε approx. = 0) \n",
    "    epsilon = np.nextafter(0,1)\n",
    "    p_ij = np.maximum(p_ij,epsilon)\n",
    "\n",
    "    print(\"Completed Pairwise Affinities Matrix. \\n\")\n",
    "\n",
    "    return p_ij\n",
    "\n",
    "def grid_search(diff_i, i, perplexity):\n",
    "\n",
    "    '''\n",
    "    Helper function to obtain sigma's based on user-specified perplexity.\n",
    "    '''\n",
    "\n",
    "    result = np.inf # Set first result to be infinity\n",
    "\n",
    "    norm = np.linalg.norm(diff_i, axis=1)\n",
    "    std_norm = np.std(norm) # Use standard deviation of norms to define search space\n",
    "\n",
    "    for sigma_search in np.linspace(0.01*std_norm,5*std_norm,200):\n",
    "\n",
    "        # Equation 1 Numerator\n",
    "        p = np.exp(-norm**2/(2*sigma_search**2)) \n",
    "\n",
    "        # Set p = 0 when i = j\n",
    "        p[i] = 0 \n",
    "\n",
    "        # Equation 1 (ε -> 0) \n",
    "        epsilon = np.nextafter(0,1)\n",
    "        p_new = np.maximum(p/np.sum(p),epsilon)\n",
    "        \n",
    "        # Shannon Entropy\n",
    "        H = -np.sum(p_new*np.log2(p_new))\n",
    "        \n",
    "        # Get log(perplexity equation) as close to equality\n",
    "        if np.abs(np.log(perplexity) - H * np.log(2)) < np.abs(result):\n",
    "            result = np.log(perplexity) - H * np.log(2)\n",
    "            sigma = sigma_search\n",
    "    \n",
    "    return sigma\n",
    "\n",
    "def get_symmetric_p_ij(p_ij:np.array([])):\n",
    "\n",
    "    '''\n",
    "    Function to obtain symmetric affinities matrix utilized in t-SNE.\n",
    "    '''\n",
    "        \n",
    "    print(\"Computing Symmetric p_ij matrix....\")\n",
    "\n",
    "    n = len(p_ij)\n",
    "    p_ij_symmetric = np.zeros(shape=(n,n))\n",
    "    for i in range(0,n):\n",
    "        for j in range(0,n):\n",
    "            p_ij_symmetric[i,j] = (p_ij[i,j] + p_ij[j,i]) / (2*n)\n",
    "    \n",
    "    # Set 0 values to minimum numpy value (ε approx. = 0)\n",
    "    epsilon = np.nextafter(0,1)\n",
    "    p_ij_symmetric = np.maximum(p_ij_symmetric,epsilon)\n",
    "\n",
    "    print(\"Completed Symmetric p_ij Matrix. \\n\")\n",
    "\n",
    "    return p_ij_symmetric\n",
    "\n",
    "def initialization(X: np.array([]),\n",
    "                   n_dimensions = 2):\n",
    "\n",
    "    return np.random.normal(loc=0,scale=1e-4,size=(len(X),n_dimensions))\n",
    "\n",
    "def get_low_dimensional_affinities(Y:np.array([])):\n",
    "    '''\n",
    "    Obtain low-dimensional affinities.\n",
    "    '''\n",
    "\n",
    "    n = len(Y)\n",
    "    q_ij = np.zeros(shape=(n,n))\n",
    "\n",
    "    for i in range(0,n):\n",
    "\n",
    "        # Equation 4 Numerator\n",
    "        diff = Y[i]-Y\n",
    "        norm = np.linalg.norm(diff, axis=1)\n",
    "        q_ij[i,:] = (1+norm**2)**(-1)\n",
    "\n",
    "    # Set p = 0 when j = i\n",
    "    np.fill_diagonal(q_ij, 0)\n",
    "\n",
    "    # Equation 4 \n",
    "    q_ij = q_ij/q_ij.sum()\n",
    "\n",
    "    # Set 0 values to minimum numpy value (ε approx. = 0)\n",
    "    epsilon = np.nextafter(0,1)\n",
    "    q_ij = np.maximum(q_ij,epsilon)\n",
    "\n",
    "    return q_ij\n",
    "def get_gradient(p_ij: np.array([]),\n",
    "                q_ij: np.array([]),\n",
    "                Y: np.array([])):\n",
    "    '''\n",
    "    Obtain gradient of cost function at current point Y.\n",
    "    '''\n",
    "\n",
    "    n = len(p_ij)\n",
    "\n",
    "    # Compute gradient\n",
    "    gradient = np.zeros(shape=(n, Y.shape[1]))\n",
    "    for i in range(0,n):\n",
    "\n",
    "        # Equation 5\n",
    "        diff = Y[i]-Y\n",
    "        A = np.array([(p_ij[i,:] - q_ij[i,:])])\n",
    "        B = np.array([(1+np.linalg.norm(diff,axis=1))**(-1)])\n",
    "        C = diff\n",
    "        gradient[i] = 4 * np.sum((A * B).T * C, axis=0)\n",
    "\n",
    "    return gradient  \n",
    "\n",
    "def tSNE(X: np.array([]), \n",
    "        perplexity = 10,\n",
    "        T = 1000, \n",
    "        eta = 200,\n",
    "        early_exaggeration = 4,\n",
    "        n_dimensions = 2):\n",
    "    \n",
    "    n = len(X)\n",
    "\n",
    "    # Get original affinities matrix \n",
    "    p_ij = get_original_pairwise_affinities(X, perplexity)\n",
    "    p_ij_symmetric = get_symmetric_p_ij(p_ij)\n",
    "    \n",
    "    # Initialization\n",
    "    Y = np.zeros(shape=(T, n, n_dimensions))\n",
    "    Y_minus1 = np.zeros(shape=(n, n_dimensions))\n",
    "    Y[0] = Y_minus1\n",
    "    Y1 = initialization(X, n_dimensions)\n",
    "    Y[1] = np.array(Y1)\n",
    "\n",
    "    print(\"Optimizing Low Dimensional Embedding....\")\n",
    "    # Optimization\n",
    "    for t in range(1, T-1):\n",
    "        \n",
    "        # Momentum & Early Exaggeration\n",
    "        if t < 250:\n",
    "            alpha = 0.5\n",
    "            early_exaggeration = early_exaggeration\n",
    "        else:\n",
    "            alpha = 0.8\n",
    "            early_exaggeration = 1\n",
    "\n",
    "        # Get Low Dimensional Affinities\n",
    "        q_ij = get_low_dimensional_affinities(Y[t])\n",
    "\n",
    "        # Get Gradient of Cost Function\n",
    "        gradient = get_gradient(early_exaggeration*p_ij_symmetric, q_ij, Y[t])\n",
    "\n",
    "        # Update Rule\n",
    "        Y[t+1] = Y[t] - eta * gradient + alpha * (Y[t] - Y[t-1]) # Use negative gradient \n",
    "\n",
    "        # Compute current value of cost function\n",
    "        if t % 50 == 0 or t == 1:\n",
    "            cost = np.sum(p_ij_symmetric * np.log(p_ij_symmetric / q_ij))\n",
    "            print(f\"Iteration {t}: Value of Cost Function is {cost}\")\n",
    "\n",
    "    print(f\"Completed Embedding: Final Value of Cost Function is {np.sum(p_ij_symmetric * np.log(p_ij_symmetric / q_ij))}\")\n",
    "    solution = Y[-1]\n",
    "\n",
    "    return solution, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y,_ = tSNE(conv_features)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
